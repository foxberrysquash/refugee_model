{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0d9b1c-dcbf-4e09-9af1-695408ebe866",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Papers:\n",
    "## EvolveGCN\n",
    "#https://jiechenjiechen.github.io/pub/evolvegcn.pdf\n",
    "#Code:https://github.com/IBM/EvolveGCN\n",
    "## Nature paper (Evolve + Attention)\n",
    "#file:///C:/Users/Christian/Downloads/s41598-023-50977-6.pdf\n",
    "## Efficent TGN\n",
    "#https://dl.acm.org/doi/pdf/10.1145/3627673.3679104\n",
    "#PyG\n",
    "#https://pytorch-geometric.readthedocs.io/en/latest/index.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f376728a-2639-49a1-b330-328435b28454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# Home-made functions\n",
    "from utils import year_to_t, unweight_adj, log_transform, exp_transform, get_link\n",
    "from utils.plot import plot_loss, plot_roc\n",
    "\n",
    "from make_data import load_edges, load_features, prepare_language, prepare_data\n",
    "from model import EGCU_H\n",
    "from mlp import LinkPredictorMLP\n",
    "from training import train\n",
    "from eval import eval_baseline, eval_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ab3324-308e-49d9-a6a3-21cc0be2f43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f20d64b-9d13-4d05-a5e3-8cef190ed1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data paths\n",
    "PATH_NF = \"data/input/\"\n",
    "PATH_E = \"data/observation/\"\n",
    "\n",
    "\n",
    "# Data preperations\n",
    "years = np.arange(1992,2019 + 1)\n",
    "time_steps = len(years)\n",
    "countries_codes = pd.read_csv(PATH_NF + \"Country_codes_names.csv\")\n",
    "nodes = len(countries_codes)\n",
    "countries = list(countries_codes[\"Name\"])\n",
    "codes = list(countries_codes[\"Code\"])\n",
    "country_number = countries_codes[\"No\"].to_numpy() - 1\n",
    "languages = list(pd.read_csv(PATH_NF + \"Legend_Language.csv\")[\"Language\"])\n",
    "# node id (number) -> Country name\n",
    "dict_country = dict(zip(country_number,countries))\n",
    "dict_code = dict(zip(country_number,codes))\n",
    "dict_code_to_country = dict(zip(codes,countries))\n",
    "dict_code_to_number = dict(zip(codes,country_number))\n",
    "dict_code_to_language = dict(enumerate(languages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f22ee1-91f4-4169-a76c-d67d146a1ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load features\n",
    "feature_names = [\"GDP\",\"GINI\",\"HDI\",\"PTS\",\"U5M\"]\n",
    "X_np, non_nan_idx = load_features(PATH_node_features=PATH_NF,years=years,feature_names=feature_names, remove_nan = True)\n",
    "n_to_country_non_nan = np.array(countries)[non_nan_idx]\n",
    "# Load edges\n",
    "A_np = load_edges(PATH_EDGES=PATH_E,log_transfrom_data=True, \n",
    "                  remove_self_loops=False, non_nan_idx=non_nan_idx, mode = \"refugee\", years_range = np.arange(1992,2019 + 1))\n",
    "# Prepare language data\n",
    "LAN_np = prepare_language(PATH=PATH_NF, non_nan_idx=non_nan_idx)\n",
    "A_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e55bc58-01ab-4d15-9e3a-d8c841fcd045",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get test data\n",
    "years1 = np.arange(1992,2020 + 1)\n",
    "X_np1, non_nan_idx1 = load_features(PATH_node_features=PATH_NF,years=years1,feature_names=feature_names, remove_nan = True)\n",
    "A_np1 = load_edges(PATH_EDGES=PATH_E,log_transfrom_data=True, \n",
    "                  remove_self_loops=False, non_nan_idx=non_nan_idx, mode = \"refugee\", years_range = years1)\n",
    "# Prepare language data\n",
    "LAN_np1 = prepare_language(PATH=PATH_NF, non_nan_idx=non_nan_idx1)\n",
    "\n",
    "A1 = torch.from_numpy(A_np1)\n",
    "X1 = torch.from_numpy(X_np1)\n",
    "\n",
    "embedding_dim = 4\n",
    "data1 = prepare_data(A1,X1, tt_idx = 28, embedding_dim=embedding_dim, \n",
    "                    LAN_np = LAN_np, weighted = True) # Set LAN_np = None to train without language embeddings\n",
    "A_norm1,X_norm1,A_train1,A_valid,X_test1 = data1\n",
    "A_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfedee3-1dd5-4077-8c36-555d4b26aa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weighted learning (GCN_MA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0930671-3dc8-4235-a3a4-d5b1312be63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters Grid Search\n",
    "\n",
    "from itertools import product\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'hidden_dim': [32, 64, 128],\n",
    "#    'output_dim': [8, 16, 32],\n",
    "#    'num_gcn_layers': [1, 2, 3],\n",
    "#    'num_heads': [2, 4, 8],\n",
    "    'learning_rate': [0.001, 0.0005, 0.0001],\n",
    "    'edge_subset': [100, 200, 300],\n",
    "#    'loss_weights': [[1.0, 1.0], [1.5, 0.5], [0.5, 1.5]],\n",
    "}\n",
    "\n",
    "grid = ParameterGrid(param_grid)\n",
    "\n",
    "# Device setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Placeholder for best parameters and lowest loss\n",
    "best_params = None\n",
    "lowest_loss = float('inf')\n",
    "\n",
    "# Grid search\n",
    "for params in grid:\n",
    "    print(f\"Testing configuration: {params}\")\n",
    "    \n",
    "    # Unpack parameters\n",
    "    hidden_dim = params['hidden_dim']\n",
    "#    output_dim = params['output_dim']\n",
    "#    num_gcn_layers = params['num_gcn_layers']\n",
    "#    num_heads = params['num_heads']\n",
    "    learning_rate = params['learning_rate']\n",
    "    edge_subset = params['edge_subset']\n",
    "#    loss_weights = params['loss_weights']\n",
    "\n",
    "    # Initialize model and optimizer with the current set of hyperparameters\n",
    "    GCN_MA = EGCU_H(\n",
    "        input_dim=X_norm.shape[-1], \n",
    "        hidden_dim=hidden_dim, \n",
    "        output_dim=output_dim, \n",
    "        num_gcn_layers=num_gcn_layers, \n",
    "        num_heads=num_heads, \n",
    "        attention=True\n",
    "    ).to(device)\n",
    "\n",
    "    link_predictor = LinkPredictorMLP(input_dim=output_dim, weighted=True).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(\n",
    "        list(GCN_MA.parameters()) + list(link_predictor.parameters()), \n",
    "        lr=learning_rate\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    losses = train(\n",
    "        X_norm=X_norm, A_norm=A_norm, A_train=A_train,\n",
    "        model=GCN_MA, link_predictor=link_predictor,\n",
    "        criterion=criterion, optimizer=optimizer, device=device,\n",
    "        num_epochs=50,  # Use fewer epochs during grid search for efficiency\n",
    "        edge_subset=edge_subset, loss_weights=loss_weights,\n",
    "        calc_reverse=True, save_at=10, weighted=True\n",
    "    )\n",
    "    \n",
    "    # Evaluate the model\n",
    "    loss_all = False\n",
    "    _, eval_loss = eval_model(\n",
    "        X_norm=X_norm, A_norm=A_norm, A_test=A_test,\n",
    "        model=GCN_MA, link_predictor=link_predictor, \n",
    "        device=device, loss_all=loss_all, weighted=True\n",
    "    )\n",
    "    print(f\"Evaluation loss for this configuration: {eval_loss}\")\n",
    "\n",
    "    # Update best parameters if current configuration is better\n",
    "    if eval_loss < lowest_loss:\n",
    "        lowest_loss = eval_loss\n",
    "        best_params = params\n",
    "\n",
    "print(\"\\nGrid Search Complete\")\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Lowest loss: {lowest_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7649b0-e917-4845-b1e5-35f4721bbde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build best model\n",
    "\n",
    "A = torch.from_numpy(A_np)\n",
    "X = torch.from_numpy(X_np)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "## Train Test Index\n",
    "# Now 80 % is training and 20 % is test\n",
    "tt_idx = 23\n",
    "embedding_dim = 4\n",
    "data = prepare_data(A,X, tt_idx = tt_idx, embedding_dim=embedding_dim, \n",
    "                    LAN_np = LAN_np, weighted = True) # Set LAN_np = None to train without language embeddings\n",
    "A_norm,X_norm,A_train,A_test,X_test = data\n",
    "\n",
    "## Hyperparameters\n",
    "# Training\n",
    "num_epochs = 1000                # Number of training epochs\n",
    "edge_subset = best_params['edge_subset'] # best_params['edge_subset'] = 200   # Number of edges to sample during training\n",
    "calc_reverse = True           # Include reverse order calc of pairs\n",
    "learning_rate = best_params['learning_rate'] # best_params['learning_rate'] = 0.0001    \n",
    "loss_weights = [1.,1.]          # Balance positive/negative loss\n",
    "# Model\n",
    "input_dim = X_norm.shape[-1]    # F: feature dimension\n",
    "hidden_dim = best_params['hidden_dim'] # best_params['hidden_dim'] = 32   \n",
    "output_dim = 16                 # Output dimension of GCN\n",
    "num_gcn_layers = 2              # Number of GCN layers\n",
    "num_heads = 4                   # Number of attention heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1181f946-2dd6-42b8-a2ea-6f4913eeb157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model, loss, and optimizer\n",
    "GCN_MA = EGCU_H(input_dim=input_dim, \n",
    "                hidden_dim=hidden_dim, \n",
    "                output_dim=output_dim, \n",
    "                num_gcn_layers=num_gcn_layers,\n",
    "                num_heads = num_heads,\n",
    "                attention = True)\n",
    "\n",
    "# Set tensors to device\n",
    "GCN_MA.to(device)\n",
    "\n",
    "link_predictor = LinkPredictorMLP(input_dim=output_dim, weighted=True).to(device) \n",
    "criterion = nn.MSELoss()         \n",
    "optimizer = optim.Adam(list(GCN_MA.parameters()) + list(link_predictor.parameters()), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77680f61-9f00-44cd-bb3d-b4f24d544317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "losses = train(X_norm=X_norm,A_norm=A_norm,A_train=A_train,\n",
    "               model=GCN_MA,link_predictor=link_predictor,\n",
    "               criterion=criterion,optimizer=optimizer,device=device,\n",
    "               num_epochs=num_epochs,edge_subset=edge_subset, loss_weights=loss_weights,\n",
    "               calc_reverse=calc_reverse,save_at = 50, weighted = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ac4129-7f86-48ad-8d17-ae7acb680b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluation\n",
    "loss_all = False\n",
    "A_pred, loss = eval_model(X_norm,A_norm,A_test,model=GCN_MA,link_predictor=link_predictor, device=device,\n",
    "                          loss_all = loss_all, weighted=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c89854-e145-4290-9ea8-7e69adf997db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten labels and predictions\n",
    "labels = A_test.to_dense().reshape(-1)\n",
    "predictions = A_pred.reshape(-1)\n",
    "\n",
    "# Debug shapes\n",
    "print(\"Labels shape:\", labels.shape)\n",
    "print(\"Predictions shape:\", predictions.shape)\n",
    "\n",
    "# Match sizes if needed\n",
    "min_size = min(labels.shape[0], predictions.shape[0])\n",
    "labels = labels[:min_size]\n",
    "predictions = predictions[:min_size]\n",
    "\n",
    "# Threshold the labels to binary\n",
    "binary_labels = (labels > 0).int()\n",
    "\n",
    "# Ensure predictions are valid for ROC computation\n",
    "predictions = predictions.cpu().detach().numpy()\n",
    "binary_labels = binary_labels.cpu().detach().numpy()\n",
    "\n",
    "# Plot the ROC curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fpr, tpr, _ = roc_curve(binary_labels, predictions)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color=\"blue\", lw=2, label=f\"ROC curve (area = {roc_auc:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], color=\"gray\", lw=2, linestyle=\"--\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve for Weighted Model\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"ROC AUC (Weighted Model): {roc_auc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d2d79a-27db-400f-af20-f97243b5347b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995a137c-a82d-42a0-ac60-fb21e384505d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c501a6-d18c-45f3-9d09-b97cbe29014b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding hubs\n",
    "#average metrics across years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076779a4-0865-433b-aeae-7b7f77e31ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Derive filtered_countries from dict_country and non_nan_idx\n",
    "countries = list(dict_country.values())\n",
    "countries = [country.replace(\"United Kingdom of Great Britain and Northern Ireland\", \"United Kingdom\") for country in countries]\n",
    "\n",
    "if isinstance(non_nan_idx, np.ndarray) and non_nan_idx.dtype == np.bool_:\n",
    "    non_nan_idx = np.where(non_nan_idx)[0]\n",
    "filtered_countries = [countries[i] for i in non_nan_idx]\n",
    "\n",
    "def compute_network_flow_metrics_extended(adjacency_matrix, countries):\n",
    "    \"\"\"\n",
    "    Compute extended network flow metrics for a weighted adjacency matrix.\n",
    "\n",
    "    Args:\n",
    "        adjacency_matrix: Weighted adjacency matrix (2D NumPy array).\n",
    "        countries: List of country names corresponding to the nodes.\n",
    "\n",
    "    Returns:\n",
    "        flow_metrics: Dictionary containing inflow, outflow hubs, and flow metrics.\n",
    "        flow_heterogeneity: Global metric representing flow distribution disparity.\n",
    "    \"\"\"\n",
    "    # Compute inflows (sum rows) and outflows (sum columns)\n",
    "    inflows = adjacency_matrix.sum(axis=1)  # Row sums (weighted inflows)\n",
    "    outflows = adjacency_matrix.sum(axis=0)  # Column sums (weighted outflows)\n",
    "\n",
    "    # Compute unweighted inflows and outflows\n",
    "    unweighted_matrix = (adjacency_matrix > 0).astype(int)\n",
    "    inflows_unweighted = unweighted_matrix.sum(axis=1)  # Row sums (unweighted inflows)\n",
    "    outflows_unweighted = unweighted_matrix.sum(axis=0)  # Column sums (unweighted outflows)\n",
    "\n",
    "    # Flow Efficiency (weighted)\n",
    "    flow_efficiency = inflows / (outflows + 1)  # Avoid division by zero\n",
    "\n",
    "    # Net Flow (weighted)\n",
    "    net_flow = inflows - outflows\n",
    "\n",
    "    # Flow Ratio (weighted)\n",
    "    flow_ratio = inflows / (inflows + outflows + 1)  # Avoid division by zero\n",
    "\n",
    "    # Flow Density (weighted)\n",
    "    max_possible_flow = adjacency_matrix.sum()  # Total flow in the network\n",
    "    total_flow = inflows + outflows\n",
    "    flow_density = total_flow / max_possible_flow\n",
    "\n",
    "    # Flow Heterogeneity (Global metric, weighted)\n",
    "    heterogeneity_index = 1 - (np.sum(total_flow**2) / (np.sum(total_flow)**2))\n",
    "\n",
    "    # Normalize inflows and outflows for hub scores (weighted)\n",
    "    max_inflow = inflows.max() if inflows.max() > 0 else 1\n",
    "    max_outflow = outflows.max() if outflows.max() > 0 else 1\n",
    "    normalized_inflows = inflows / max_inflow\n",
    "    normalized_outflows = outflows / max_outflow\n",
    "\n",
    "    # Normalize inflows and outflows for hub scores (unweighted)\n",
    "    max_inflow_unweighted = inflows_unweighted.max() if inflows_unweighted.max() > 0 else 1\n",
    "    max_outflow_unweighted = outflows_unweighted.max() if outflows_unweighted.max() > 0 else 1\n",
    "    normalized_inflows_unweighted = inflows_unweighted / max_inflow_unweighted\n",
    "    normalized_outflows_unweighted = outflows_unweighted / max_outflow_unweighted\n",
    "\n",
    "    # Map results to country names\n",
    "    flow_metrics = {\n",
    "        \"inflow_hubs_weighted\": {countries[i]: normalized_inflows[i] for i in range(len(countries))},\n",
    "        \"outflow_hubs_weighted\": {countries[i]: normalized_outflows[i] for i in range(len(countries))},\n",
    "        \"inflow_hubs_unweighted\": {countries[i]: normalized_inflows_unweighted[i] for i in range(len(countries))},\n",
    "        \"outflow_hubs_unweighted\": {countries[i]: normalized_outflows_unweighted[i] for i in range(len(countries))},\n",
    "        \"flow_efficiency\": {countries[i]: flow_efficiency[i] for i in range(len(countries))},\n",
    "        \"flow_ratio\": {countries[i]: flow_ratio[i] for i in range(len(countries))},\n",
    "        \"flow_density\": {countries[i]: flow_density[i] for i in range(len(countries))},\n",
    "        \"net_flow\": {countries[i]: net_flow[i] for i in range(len(countries))},\n",
    "    }\n",
    "\n",
    "    return flow_metrics, heterogeneity_index\n",
    "\n",
    "# List of metrics to compute\n",
    "metrics_list = [\n",
    "    \"inflow_hubs_weighted\",\n",
    "    \"outflow_hubs_weighted\",\n",
    "    \"inflow_hubs_unweighted\",\n",
    "    \"outflow_hubs_unweighted\",\n",
    "    \"flow_efficiency\",\n",
    "    \"flow_ratio\",\n",
    "    \"flow_density\",\n",
    "    \"net_flow\",\n",
    "]\n",
    "\n",
    "# Initialize data structures to store metrics over time\n",
    "num_years = A_np.shape[0]  # Number of years\n",
    "metrics_over_time = {\n",
    "    metric: {country: [] for country in filtered_countries} for metric in metrics_list\n",
    "}\n",
    "heterogeneity_index_over_time = []\n",
    "\n",
    "# Loop over each year to compute metrics\n",
    "for t in range(num_years):\n",
    "    adjacency_matrix_t = A_np[t, :, :]\n",
    "    adjacency_matrix_t = np.nan_to_num(adjacency_matrix_t)  # Replace NaNs with 0\n",
    "\n",
    "    # Compute metrics for the year\n",
    "    flow_metrics_t, heterogeneity_index_t = compute_network_flow_metrics_extended(\n",
    "        adjacency_matrix_t, filtered_countries\n",
    "    )\n",
    "\n",
    "    # Store metrics for each country\n",
    "    for metric in metrics_list:\n",
    "        for country in filtered_countries:\n",
    "            value = flow_metrics_t[metric][country]\n",
    "            metrics_over_time[metric][country].append(value)\n",
    "\n",
    "    # Store heterogeneity index\n",
    "    heterogeneity_index_over_time.append(heterogeneity_index_t)\n",
    "\n",
    "# Compute average metrics over the years\n",
    "average_metrics = {}\n",
    "for metric in metrics_list:\n",
    "    average_metrics[metric] = {}\n",
    "    for country in filtered_countries:\n",
    "        values = metrics_over_time[metric][country]\n",
    "        average_value = np.mean(values)\n",
    "        average_metrics[metric][country] = average_value\n",
    "\n",
    "# Compute average heterogeneity index\n",
    "average_heterogeneity_index = np.mean(heterogeneity_index_over_time)\n",
    "\n",
    "# Display results for average weighted and unweighted hubs\n",
    "print(\"\\nTop 5 Weighted Inflow Hubs (Average over Years):\")\n",
    "for country, score in sorted(average_metrics[\"inflow_hubs_weighted\"].items(), key=lambda x: x[1], reverse=True)[:5]:\n",
    "    print(f\"{country}: {score:.4f}\")\n",
    "\n",
    "print(\"\\nTop 5 Weighted Outflow Hubs (Average over Years):\")\n",
    "for country, score in sorted(average_metrics[\"outflow_hubs_weighted\"].items(), key=lambda x: x[1], reverse=True)[:5]:\n",
    "    print(f\"{country}: {score:.4f}\")\n",
    "\n",
    "print(\"\\nTop 5 Unweighted Inflow Hubs (Average over Years):\")\n",
    "for country, score in sorted(average_metrics[\"inflow_hubs_unweighted\"].items(), key=lambda x: x[1], reverse=True)[:5]:\n",
    "    print(f\"{country}: {score:.4f}\")\n",
    "\n",
    "print(\"\\nTop 5 Unweighted Outflow Hubs (Average over Years):\")\n",
    "for country, score in sorted(average_metrics[\"outflow_hubs_unweighted\"].items(), key=lambda x: x[1], reverse=True)[:5]:\n",
    "    print(f\"{country}: {score:.4f}\")\n",
    "\n",
    "print(\"\\nTop 5 Countries by Flow Efficiency (Weighted) (Average over Years):\")\n",
    "for country, score in sorted(average_metrics[\"flow_efficiency\"].items(), key=lambda x: x[1], reverse=True)[:5]:\n",
    "    print(f\"{country}: {score:.4f}\")\n",
    "\n",
    "print(\"\\nTop 5 Countries by Flow Ratio (Average over Years):\")\n",
    "for country, score in sorted(average_metrics[\"flow_ratio\"].items(), key=lambda x: x[1], reverse=True)[:5]:\n",
    "    print(f\"{country}: {score:.4f}\")\n",
    "\n",
    "print(\"\\nTop 5 Countries by Flow Density (Average over Years):\")\n",
    "for country, score in sorted(average_metrics[\"flow_density\"].items(), key=lambda x: x[1], reverse=True)[:5]:\n",
    "    print(f\"{country}: {score:.4f}\")\n",
    "\n",
    "print(f\"\\nAverage Flow Heterogeneity Index (Global): {average_heterogeneity_index:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7866d274-966b-4734-ad28-aec93d4ab233",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_top_metrics(flow_metrics, title, metric_key, top_n=5):\n",
    "    \"\"\"\n",
    "    Visualize the top countries for a given metric.\n",
    "    \n",
    "    Args:\n",
    "        flow_metrics: Dictionary containing flow metrics.\n",
    "        title: Title for the plot.\n",
    "        metric_key: Key in the flow_metrics dictionary to visualize.\n",
    "        top_n: Number of top countries to display.\n",
    "    \"\"\"\n",
    "    # Sort and extract top N countries\n",
    "    sorted_metrics = sorted(flow_metrics[metric_key].items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "    countries = [item[0] for item in sorted_metrics]\n",
    "    scores = [item[1] for item in sorted_metrics]\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(5, 3))\n",
    "    plt.barh(countries, scores, color='skyblue')\n",
    "    plt.xlabel('Score')\n",
    "    plt.title(title)\n",
    "    plt.gca().invert_yaxis()  # Invert y-axis to have the highest score at the top\n",
    "    \n",
    "    # Despine\n",
    "    ax = plt.gca()\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_bottom_metrics(flow_metrics, title, metric_key, bottom_n=5):\n",
    "    \"\"\"\n",
    "    Visualize the least-performing countries for a given metric.\n",
    "    \n",
    "    Args:\n",
    "        flow_metrics: Dictionary containing flow metrics.\n",
    "        title: Title for the plot.\n",
    "        metric_key: Key in the flow_metrics dictionary to visualize.\n",
    "        bottom_n: Number of bottom countries to display.\n",
    "    \"\"\"\n",
    "    # Sort and extract bottom N countries\n",
    "    sorted_metrics = sorted(flow_metrics[metric_key].items(), key=lambda x: x[1])[:bottom_n]\n",
    "    countries = [item[0] for item in sorted_metrics]\n",
    "    scores = [item[1] for item in sorted_metrics]\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(5, 3))\n",
    "    plt.barh(countries, scores, color='salmon')\n",
    "    plt.xlabel('Score')\n",
    "    plt.title(title)\n",
    "    plt.gca().invert_yaxis()  # Invert y-axis to have the highest score at the top\n",
    "    \n",
    "    # Despine\n",
    "    ax = plt.gca()\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize top metrics\n",
    "visualize_top_metrics(average_metrics, \"Top 5 Weighted Inflow Hubs\", \"inflow_hubs_weighted\")\n",
    "visualize_top_metrics(average_metrics, \"Top 5 Weighted Outflow Hubs\", \"outflow_hubs_weighted\")\n",
    "visualize_top_metrics(average_metrics, \"Top 5 Unweighted Inflow Hubs\", \"inflow_hubs_unweighted\")\n",
    "visualize_top_metrics(average_metrics, \"Top 5 Unweighted Outflow Hubs\", \"outflow_hubs_unweighted\")\n",
    "visualize_top_metrics(average_metrics, \"Top 5 Countries by Flow Efficiency\", \"flow_efficiency\")\n",
    "visualize_top_metrics(average_metrics, \"Top 5 Countries by Flow Ratio\", \"flow_ratio\")\n",
    "visualize_top_metrics(average_metrics, \"Top 5 Countries by Flow Density\", \"flow_density\")\n",
    "\n",
    "# Visualize bottom metrics\n",
    "visualize_bottom_metrics(average_metrics, \"Bottom 10 Countries by Flow Efficiency\", \"flow_efficiency\", bottom_n=10)\n",
    "\n",
    "# Global Flow Heterogeneity Index\n",
    "print(f\"\\nFlow Heterogeneity Index (Global): {flow_heterogeneity:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834eecc4-e71a-4e4b-a903-6238dbd851a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3998f1-6df5-4968-9229-fc2edbc0ff68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#T -> T+1 (28 -> 29) validation\n",
    "countries = [country.replace(\"United Kingdom of Great Britain and Northern Ireland\", \"United Kingdom\") for country in countries]\n",
    "filtered_countries = [country.replace(\"United Kingdom of Great Britain and Northern Ireland\", \"UK\") for country in filtered_countries]\n",
    "filtered_countries = [country.replace(\"United Kingdom\", \"UK\") for country in filtered_countries]\n",
    "filtered_countries = [country.replace(\"United States of America\", \"USA\") for country in filtered_countries]\n",
    "filtered_countries = [country.replace(\"Syrian Arab Republic\", \"Syria\") for country in filtered_countries]\n",
    "filtered_countries = [country.replace(\"Iran (Islamic Republic of)\", \"Iran\") for country in filtered_countries]\n",
    "filtered_countries = [country.replace(\"Venezuela (Bolivarian Republic of)\", \"Venezuela\") for country in filtered_countries]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1b110d-099c-413c-b070-09d0a456edd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_E = \"data/observation/\"\n",
    "years1 = np.arange(1992,2020 + 1)\n",
    "feature_names = [\"GDP\",\"GINI\",\"HDI\",\"PTS\",\"U5M\"]\n",
    "X_np1, non_nan_idx1 = load_features(PATH_node_features=PATH_NF,years=years1,feature_names=feature_names, remove_nan = True)\n",
    "A_np1 = load_edges(PATH_EDGES=PATH_E,log_transfrom_data=True, \n",
    "                  remove_self_loops=False, non_nan_idx=non_nan_idx, mode = \"refugee\", years_range = years1)\n",
    "# Prepare language data\n",
    "LAN_np1 = prepare_language(PATH=PATH_NF, non_nan_idx=non_nan_idx1)\n",
    "\n",
    "A1 = torch.from_numpy(A_np1)\n",
    "X1 = torch.from_numpy(X_np1)\n",
    "\n",
    "data1 = prepare_data(A1,X1, tt_idx = 28, embedding_dim=embedding_dim, \n",
    "                    LAN_np = LAN_np, weighted = True) # Set LAN_np = None to train without language embeddings\n",
    "\n",
    "A_norm1,X_norm1,A_train1,A_valid,X_test1 = data1\n",
    "print(A_norm1.shape)\n",
    "A_pred1, loss1 = eval_model(X_norm1,A_norm1,A_valid,model=GCN_MA,link_predictor=link_predictor, device=device,\n",
    "                          loss_all = loss_all, weighted=True, predict_indx=-1)\n",
    "\n",
    "A_pred_denoised = A_pred1.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bf6e13-8260-4480-a188-f38a71d699f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_E = \"data/observation/\"\n",
    "A_np29 = load_edges(PATH_EDGES=PATH_E,log_transfrom_data=True, \n",
    "                  remove_self_loops=False, non_nan_idx=non_nan_idx, mode = \"refugee\") #,years_range = np.arange(1992,2019 + 1))\n",
    "A_np29 = A_np29[-1, :, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c031c8a-a483-436a-9907-1e73bab995aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = ((A_pred_denoised.cpu().detach().numpy() - A_np29) ** 2).mean()\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "mae = np.abs(A_pred_denoised.cpu().detach().numpy() - A_np29).mean()\n",
    "print(f\"Mean Absolute Error: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2ebfa5-17dc-4182-bf08-163d31d7e17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def visualize_matrix_difference(A_pred, A_actual, title=\"Difference Between Predicted and Actual\"):\n",
    "    \"\"\"\n",
    "    Visualize the difference between the predicted and actual adjacency matrices.\n",
    "\n",
    "    Args:\n",
    "        A_pred: Predicted adjacency matrix (2D array or tensor).\n",
    "        A_actual: Actual adjacency matrix (2D array or tensor).\n",
    "        title: Title for the heatmap.\n",
    "    \"\"\"\n",
    "    # Ensure both matrices are NumPy arrays\n",
    "    if isinstance(A_pred, torch.Tensor):\n",
    "        A_pred = A_pred.cpu().detach().numpy()\n",
    "    if isinstance(A_actual, torch.Tensor):\n",
    "        A_actual = A_actual.cpu().detach().numpy()\n",
    "\n",
    "    # Compute the difference\n",
    "    difference_matrix = A_pred - A_actual\n",
    "\n",
    "    # Create the heatmap\n",
    "    plt.figure(figsize=(7.5, 6))\n",
    "    sns.heatmap(\n",
    "        difference_matrix,\n",
    "        cmap=\"coolwarm\",\n",
    "        center=0,\n",
    "        cbar_kws={'label': 'Difference'},\n",
    "        xticklabels=False,\n",
    "        yticklabels=False\n",
    "    )\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.xlabel(\"Countries\")\n",
    "    plt.ylabel(\"Countries\")\n",
    "    plt.show()\n",
    "\n",
    "# Visualize the difference\n",
    "visualize_matrix_difference(A_pred_denoised, A_np29, title=\"Difference Between Predicted and Actual Matrices\")\n",
    "\n",
    "# Optional: Visualize the individual matrices\n",
    "def visualize_matrix(A, title=\"Matrix Visualization\"):\n",
    "    \"\"\"\n",
    "    Visualize a single matrix as a heatmap.\n",
    "    \n",
    "    Args:\n",
    "        A: Matrix (2D array or tensor).\n",
    "        title: Title for the heatmap.\n",
    "    \"\"\"\n",
    "    if isinstance(A, torch.Tensor):\n",
    "        A = A.cpu().detach().numpy()\n",
    "\n",
    "    plt.figure(figsize=(7.5, 6))\n",
    "    sns.heatmap(\n",
    "        A,\n",
    "        cmap=\"viridis\",\n",
    "        cbar_kws={'label': 'Value'},\n",
    "        xticklabels=False,\n",
    "        yticklabels=False\n",
    "    )\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.xlabel(\"Countries\")\n",
    "    plt.ylabel(\"Countries\")\n",
    "    plt.show()\n",
    "\n",
    "# Visualize the predicted and actual matrices individually\n",
    "visualize_matrix(A_pred_denoised, title=\"Predicted Adjacency Matrix\")\n",
    "visualize_matrix(A_np29, title=\"Observed Adjacency Matrix\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7bbe30-66c3-4f45-96de-84b5fcab2852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure A_pred_denoised and A_np29 are NumPy arrays\n",
    "A_pred_denoised_np = A_pred_denoised.cpu().detach().numpy()\n",
    "\n",
    "# ------------------------------\n",
    "# 1. Check the Range of Values\n",
    "# ------------------------------\n",
    "print(f\"A_np29 range: {A_np29.min()} to {A_np29.max()}\")\n",
    "print(f\"A_pred_denoised range: {A_pred_denoised_np.min()} to {A_pred_denoised_np.max()}\")\n",
    "\n",
    "# ------------------------------\n",
    "# 2. Compute Sparsity of A_np29\n",
    "# ------------------------------\n",
    "sparsity = np.mean(A_np29 == 0)\n",
    "print(f\"Sparsity of A_np29: {sparsity:.2%}\")\n",
    "sparsity = np.mean(A_pred_denoised_np == 0)\n",
    "print(f\"Sparsity of A_pred_denoised_np: {sparsity:.2%}\")\n",
    "\n",
    "# ------------------------------\n",
    "# 3. Compute Mean Squared Error (MSE)\n",
    "# ------------------------------\n",
    "mse = ((A_pred_denoised_np - A_np29) ** 2).mean()\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "# ------------------------------\n",
    "# 4. Compute Mean Absolute Error (MAE)\n",
    "# ------------------------------\n",
    "mae = np.abs(A_pred_denoised_np - A_np29).mean()\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "\n",
    "# ------------------------------\n",
    "# 5. Compare with a Baseline Model\n",
    "# ------------------------------\n",
    "# Example baseline: predict the last observed adjacency matrix as the next one\n",
    "A_baseline = A_np29.copy()  # Assuming no change as the baseline\n",
    "baseline_mse = ((A_baseline - A_np29) ** 2).mean()\n",
    "print(f\"Baseline MSE: {baseline_mse}\")\n",
    "\n",
    "# ------------------------------\n",
    "# 6. Visualize Absolute Error Distribution\n",
    "# ------------------------------\n",
    "errors = np.abs(A_pred_denoised_np - A_np29).flatten()\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(errors, bins=50, alpha=0.7, color=\"blue\", edgecolor=\"black\")\n",
    "plt.title(\"Distribution of Absolute Errors\", fontsize=16)\n",
    "plt.xlabel(\"Absolute Error\", fontsize=14)\n",
    "plt.ylabel(\"Frequency\", fontsize=14)\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ------------------------------\n",
    "# 7. Visualize Predicted vs. Actual Adjacency Matrix with Same Scale\n",
    "# ------------------------------\n",
    "# Determine the shared scale\n",
    "vmin = min(A_np29.min(), A_pred_denoised_np.min())\n",
    "vmax = max(A_np29.max(), A_pred_denoised_np.max())\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Original Adjacency Matrix\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(A_np29, cmap=\"viridis\", vmin=vmin, vmax=vmax)  # Use shared vmin and vmax\n",
    "plt.title(\"Original Adjacency Matrix\", fontsize=14)\n",
    "plt.colorbar(label=\"Flow\")\n",
    "plt.xlabel(\"Node\")\n",
    "plt.ylabel(\"Node\")\n",
    "\n",
    "# Predicted Adjacency Matrix\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(A_pred_denoised_np, cmap=\"viridis\", vmin=vmin, vmax=vmax)  # Use shared vmin and vmax\n",
    "plt.title(\"Predicted Adjacency Matrix\", fontsize=14)\n",
    "plt.colorbar(label=\"Flow\")\n",
    "plt.xlabel(\"Node\")\n",
    "plt.ylabel(\"Node\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ------------------------------\n",
    "# 8. Summary\n",
    "# ------------------------------\n",
    "print(\"\\nSummary:\")\n",
    "print(f\"- MSE of the predicted matrix: {mse}\")\n",
    "print(f\"- Baseline MSE: {baseline_mse}\")\n",
    "print(f\"- Sparsity of A_np29: {sparsity:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718a7d47-103f-46d4-85f2-eb7815c34ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute signed errors\n",
    "signed_errors = (A_pred_denoised_np - A_np29).flatten()  # Flatten to 1D for plotting\n",
    "\n",
    "# Plot histogram of signed error frequencies in percentages\n",
    "plt.figure(figsize=(6, 4))\n",
    "counts, bins, _ = plt.hist(signed_errors, bins=50, weights=np.ones_like(signed_errors) / len(signed_errors) * 100, \n",
    "                           alpha=0.7, color=\"blue\", edgecolor=\"black\")\n",
    "plt.title(\"Histogram of Signed Errors (Frequency in %)\", fontsize=16)\n",
    "plt.xlabel(\"Error (Predicted - Actual)\", fontsize=14)\n",
    "plt.ylabel(\"Frequency (%)\", fontsize=14)\n",
    "plt.axvline(x=0, color=\"red\", linestyle=\"--\", label=\"Zero Error\")\n",
    "#plt.legend(fontsize=12)\n",
    "plt.grid(False)\n",
    "\n",
    "# Despine\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print bins and percentages for reference\n",
    "#print(\"Signed Error Distribution (%):\")\n",
    "#for i in range(len(bins) - 1):\n",
    "#    print(f\"Range {bins[i]:.2f} to {bins[i+1]:.2f}: {counts[i]:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5b2c0f-81cf-4428-830d-1b069c7f6a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare to erf gravity model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34200249-7979-4898-b319-b6c93d6a1361",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_np29_gravity29 = pd.read_csv(\"data/Refugee_Stock_2020_Gravity_Model.csv\"\n",
    "                              , index_col=0)\n",
    "A_np29_gravity29 = A_np29_gravity29.fillna(0)\n",
    "\n",
    "max_finite_value = A_np29_gravity29[A_np29_gravity29 != np.inf].max().max()\n",
    "A_np29_gravity29 = A_np29_gravity29.replace([np.inf, -np.inf], max_finite_value)\n",
    "\n",
    "A_np29_gravity29 = np.log(A_np29_gravity29.copy() + 1)\n",
    "\n",
    "A_np29_gravity29.index = A_np29_gravity29.index - 1\n",
    "A_np29_gravity29.columns = A_np29_gravity29.columns.astype(int) - 1\n",
    "\n",
    "A_np29_gravity29 = A_np29_gravity29.iloc[:, non_nan_idx]  # Select columns\n",
    "A_np29_gravity29 = A_np29_gravity29.iloc[non_nan_idx, :]  # Select rows\n",
    "\n",
    "A_np29_gravity29 = A_np29_gravity29.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ef6896-65d7-4649-bd96-31eb76dd5ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = ((A_np29_gravity29 - A_np29) ** 2).mean()\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "mae = np.abs(A_np29_gravity29 - A_np29).mean()\n",
    "print(f\"Mean Absolute Error: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed825fee-fdd2-4664-9637-9f02769895d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def visualize_matrix_difference(A_pred, A_actual, title=\"Difference Between Predicted and Actual\"):\n",
    "    \"\"\"\n",
    "    Visualize the difference between the predicted and actual adjacency matrices.\n",
    "\n",
    "    Args:\n",
    "        A_pred: Predicted adjacency matrix (2D array or tensor).\n",
    "        A_actual: Actual adjacency matrix (2D array or tensor).\n",
    "        title: Title for the heatmap.\n",
    "    \"\"\"\n",
    "    # Ensure both matrices are NumPy arrays\n",
    "    if isinstance(A_pred, torch.Tensor):\n",
    "        A_pred = A_pred.cpu().detach().numpy()\n",
    "    if isinstance(A_actual, torch.Tensor):\n",
    "        A_actual = A_actual.cpu().detach().numpy()\n",
    "\n",
    "    # Compute the difference\n",
    "    difference_matrix = A_pred - A_actual\n",
    "\n",
    "    # Create the heatmap\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(\n",
    "        difference_matrix,\n",
    "        cmap=\"coolwarm\",\n",
    "        center=0,\n",
    "        cbar_kws={'label': 'Difference'},\n",
    "        xticklabels=False,\n",
    "        yticklabels=False\n",
    "    )\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.xlabel(\"Countries\")\n",
    "    plt.ylabel(\"Countries\")\n",
    "    plt.show()\n",
    "\n",
    "# Visualize the difference\n",
    "visualize_matrix_difference(A_np29_gravity29, A_np29, title=\"Difference Between Predicted and Actual Matrices\")\n",
    "\n",
    "# Optional: Visualize the individual matrices\n",
    "def visualize_matrix(A, title=\"Matrix Visualization\"):\n",
    "    \"\"\"\n",
    "    Visualize a single matrix as a heatmap.\n",
    "    \n",
    "    Args:\n",
    "        A: Matrix (2D array or tensor).\n",
    "        title: Title for the heatmap.\n",
    "    \"\"\"\n",
    "    if isinstance(A, torch.Tensor):\n",
    "        A = A.cpu().detach().numpy()\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(\n",
    "        A,\n",
    "        cmap=\"viridis\",\n",
    "        cbar_kws={'label': 'Value'},\n",
    "        xticklabels=False,\n",
    "        yticklabels=False\n",
    "    )\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.xlabel(\"Countries\")\n",
    "    plt.ylabel(\"Countries\")\n",
    "    plt.show()\n",
    "\n",
    "# Visualize the predicted and actual matrices individually\n",
    "visualize_matrix(A_np29_gravity29, title=\"Predicted Adjacency Matrix\")\n",
    "visualize_matrix(A_np29, title=\"Actual Adjacency Matrix\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6949347d-0cc5-49e4-8815-969971d938bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def visualize_matrix_difference(A_pred, A_actual, title=\"Difference Between Predicted and Actual\"):\n",
    "    \"\"\"\n",
    "    Visualize the difference between the predicted and actual adjacency matrices.\n",
    "\n",
    "    Args:\n",
    "        A_pred: Predicted adjacency matrix (2D array or tensor).\n",
    "        A_actual: Actual adjacency matrix (2D array or tensor).\n",
    "        title: Title for the heatmap.\n",
    "    \"\"\"\n",
    "    # Ensure both matrices are NumPy arrays\n",
    "    if isinstance(A_pred, torch.Tensor):\n",
    "        A_pred = A_pred.cpu().detach().numpy()\n",
    "    if isinstance(A_actual, torch.Tensor):\n",
    "        A_actual = A_actual.cpu().detach().numpy()\n",
    "\n",
    "    # Compute the difference\n",
    "    difference_matrix = A_pred - A_actual\n",
    "\n",
    "    # Create the heatmap\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(\n",
    "        difference_matrix,\n",
    "        cmap=\"coolwarm\",\n",
    "        center=0,\n",
    "        cbar_kws={'label': 'Difference'},\n",
    "        xticklabels=False,\n",
    "        yticklabels=False\n",
    "    )\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.xlabel(\"Countries\")\n",
    "    plt.ylabel(\"Countries\")\n",
    "    plt.show()\n",
    "\n",
    "# Visualize the difference\n",
    "visualize_matrix_difference(A_np29_gravity29, A_np29, title=\"Difference Between Predicted and Actual Matrices\")\n",
    "\n",
    "# Optional: Visualize the individual matrices\n",
    "def visualize_matrix(A, title=\"Matrix Visualization\"):\n",
    "    \"\"\"\n",
    "    Visualize a single matrix as a heatmap.\n",
    "    \n",
    "    Args:\n",
    "        A: Matrix (2D array or tensor).\n",
    "        title: Title for the heatmap.\n",
    "    \"\"\"\n",
    "    if isinstance(A, torch.Tensor):\n",
    "        A = A.cpu().detach().numpy()\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(\n",
    "        A,\n",
    "        cmap=\"viridis\",\n",
    "        cbar_kws={'label': 'Value'},\n",
    "        xticklabels=False,\n",
    "        yticklabels=False\n",
    "    )\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.xlabel(\"Countries\")\n",
    "    plt.ylabel(\"Countries\")\n",
    "    plt.show()\n",
    "\n",
    "# Visualize the predicted and actual matrices individually\n",
    "visualize_matrix(A_np29_gravity29, title=\"Predicted Denoised Adjacency Matrix\")\n",
    "visualize_matrix(A_np29, title=\"Actual Adjacency Matrix\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3ce7fa-498b-4987-8c66-8c77cae30dca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386984a7-0796-4d0c-a9e3-abf02a201be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hub validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94937d53-f2a5-4c5e-b9b7-b769a797a769",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure A_pred_denoised is a NumPy array\n",
    "A_pred_denoised_np = A_pred_denoised.cpu().detach().numpy()\n",
    "A_valid_np = A_valid.cpu().detach().numpy()  # Convert A_valid to NumPy\n",
    "\n",
    "A_valid_np = A_valid_np.squeeze(0)\n",
    "\n",
    "# Compute metrics for the validation set\n",
    "flow_metrics_valid, flow_heterogeneity_valid = compute_network_flow_metrics_extended(A_valid_np, filtered_countries)\n",
    "\n",
    "# Compute metrics for the predicted graph\n",
    "predicted_flow_metrics, predicted_flow_heterogeneity = compute_network_flow_metrics_extended(A_pred_denoised_np, filtered_countries)\n",
    "\n",
    "# -----------------------------\n",
    "# Helper function: Plot comparison for top 10 countries\n",
    "# -----------------------------\n",
    "def plot_comparison(original_data, predicted_data, title, ylabel):\n",
    "    top_10 = sorted(original_data.items(), key=lambda x: x[1], reverse=True)[:10]  # Top 10 from original\n",
    "    countries, original_values = zip(*top_10)  # Separate into country names and values\n",
    "    predicted_values = [predicted_data[country] for country in countries]  # Get corresponding predicted values\n",
    "    \n",
    "    x = np.arange(len(countries))  # X positions\n",
    "    width = 0.4  # Bar width\n",
    "\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    plt.bar(x - width / 2, original_values, width, label=\"Validation\")\n",
    "    plt.bar(x + width / 2, predicted_values, width, label=\"Predicted\")\n",
    "    plt.xticks(x, countries, rotation=45, ha=\"right\")\n",
    "    plt.title(title)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.grid(False)  # Remove grid\n",
    "    plt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# Correlation for each metric and plotting comparisons\n",
    "# -----------------------------\n",
    "\n",
    "metrics_to_compare = {\n",
    "    \"Weighted Inflow Hubs\": \"inflow_hubs_weighted\",\n",
    "    \"Weighted Outflow Hubs\": \"outflow_hubs_weighted\",\n",
    "    \"Unweighted Inflow Hubs\": \"inflow_hubs_unweighted\",\n",
    "    \"Unweighted Outflow Hubs\": \"outflow_hubs_unweighted\",\n",
    "    \"Flow Efficiency\": \"flow_efficiency\",\n",
    "    \"Flow Ratio\": \"flow_ratio\",\n",
    "    \"Flow Density\": \"flow_density\",\n",
    "}\n",
    "\n",
    "for metric_name, metric_key in metrics_to_compare.items():\n",
    "    print(f\"\\nCorrelation for {metric_name}:\")\n",
    "    corr = np.corrcoef(\n",
    "        list(flow_metrics_valid[metric_key].values()),\n",
    "        list(predicted_flow_metrics[metric_key].values())\n",
    "    )[0, 1]\n",
    "    print(f\"Correlation: {corr:.4f}\")\n",
    "\n",
    "    plot_comparison(\n",
    "        flow_metrics_valid[metric_key],\n",
    "        predicted_flow_metrics[metric_key],\n",
    "        f\"{metric_name} (Top 10)\",\n",
    "        metric_name\n",
    "    )\n",
    "\n",
    "# -----------------------------\n",
    "# 7. Flow Heterogeneity Index\n",
    "# -----------------------------\n",
    "print(\"\\nComparison of Flow Heterogeneity Index:\")\n",
    "print(f\"Validation: {flow_heterogeneity_valid:.4f}\")\n",
    "print(f\"Predicted: {predicted_flow_heterogeneity:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf57cd5a-c0e3-4c4e-88eb-5f0076cfffa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure A_pred_denoised is a NumPy array\n",
    "A_pred_denoised_np = A_np29_gravity29\n",
    "A_valid_np = A_valid.cpu().detach().numpy()  # Convert A_valid to NumPy\n",
    "A_valid_np = A_valid_np.squeeze(0)\n",
    "\n",
    "# Compute metrics for the validation set\n",
    "flow_metrics_valid, flow_heterogeneity_valid = compute_network_flow_metrics_extended(A_valid_np, filtered_countries)\n",
    "\n",
    "# Compute metrics for the predicted graph\n",
    "predicted_flow_metrics, predicted_flow_heterogeneity = compute_network_flow_metrics_extended(A_pred_denoised_np, filtered_countries)\n",
    "\n",
    "# -----------------------------\n",
    "# Helper function: Plot comparison for top 10 countries\n",
    "# -----------------------------\n",
    "def plot_comparison(original_data, predicted_data, title, ylabel):\n",
    "    top_10 = sorted(original_data.items(), key=lambda x: x[1], reverse=True)[:10]  # Top 10 from original\n",
    "    countries, original_values = zip(*top_10)  # Separate into country names and values\n",
    "    predicted_values = [predicted_data[country] for country in countries]  # Get corresponding predicted values\n",
    "    \n",
    "    x = np.arange(len(countries))  # X positions\n",
    "    width = 0.4  # Bar width\n",
    "\n",
    "def plot_comparison(original_data, predicted_data, title, ylabel):\n",
    "    top_10 = sorted(original_data.items(), key=lambda x: x[1], reverse=True)[:10]  # Top 10 from original\n",
    "    countries, original_values = zip(*top_10)  # Separate into country names and values\n",
    "    predicted_values = [predicted_data[country] for country in countries]  # Get corresponding predicted values\n",
    "    \n",
    "    x = np.arange(len(countries))  # X positions\n",
    "    width = 0.4  # Bar width\n",
    "\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    plt.bar(x - width / 2, original_values, width, label=\"Validation\")\n",
    "    plt.bar(x + width / 2, predicted_values, width, label=\"Predicted\")\n",
    "    plt.xticks(x, countries, rotation=45, ha=\"right\")\n",
    "    plt.title(title)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.grid(False)  # Remove grid\n",
    "    plt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# Correlation for each metric and plotting comparisons\n",
    "# -----------------------------\n",
    "\n",
    "metrics_to_compare = {\n",
    "    \"Weighted Inflow Hubs\": \"inflow_hubs_weighted\",\n",
    "    \"Weighted Outflow Hubs\": \"outflow_hubs_weighted\",\n",
    "    \"Unweighted Inflow Hubs\": \"inflow_hubs_unweighted\",\n",
    "    \"Unweighted Outflow Hubs\": \"outflow_hubs_unweighted\",\n",
    "    \"Flow Efficiency\": \"flow_efficiency\",\n",
    "    \"Flow Ratio\": \"flow_ratio\",\n",
    "    \"Flow Density\": \"flow_density\",\n",
    "}\n",
    "\n",
    "for metric_name, metric_key in metrics_to_compare.items():\n",
    "    print(f\"\\nCorrelation for {metric_name}:\")\n",
    "    corr = np.corrcoef(\n",
    "        list(flow_metrics_valid[metric_key].values()),\n",
    "        list(predicted_flow_metrics[metric_key].values())\n",
    "    )[0, 1]\n",
    "    print(f\"Correlation: {corr:.4f}\")\n",
    "\n",
    "    plot_comparison(\n",
    "        flow_metrics_valid[metric_key],\n",
    "        predicted_flow_metrics[metric_key],\n",
    "        f\"{metric_name} (Top 10)\",\n",
    "        metric_name\n",
    "    )\n",
    "\n",
    "# -----------------------------\n",
    "# 7. Flow Heterogeneity Index\n",
    "# -----------------------------\n",
    "print(\"\\nComparison of Flow Heterogeneity Index:\")\n",
    "print(f\"Validation: {flow_heterogeneity_valid:.4f}\")\n",
    "print(f\"Predicted: {predicted_flow_heterogeneity:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f58d786-c8c7-4fcc-80bf-274fe0b4aad9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b218f4f0-4d2d-4d24-8958-72d5ee1e83e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature importance - ablation study (retraining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3188c439-842c-4cab-a6a7-01b0b84fdc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_E = \"data/observation/\"\n",
    "years1 = np.arange(1992,2020 + 1)\n",
    "feature_names = [\"GDP\",\"GINI\",\"HDI\",\"PTS\",\"U5M\"]\n",
    "X_np1, non_nan_idx1 = load_features(PATH_node_features=PATH_NF,years=years1,feature_names=feature_names, remove_nan = True)\n",
    "A_np1 = load_edges(PATH_EDGES=PATH_E,log_transfrom_data=True, \n",
    "                  remove_self_loops=False, non_nan_idx=non_nan_idx, mode = \"refugee\", years_range = years1)\n",
    "# Prepare language data\n",
    "LAN_np1 = prepare_language(PATH=PATH_NF, non_nan_idx=non_nan_idx1)\n",
    "\n",
    "A1 = torch.from_numpy(A_np1)\n",
    "X1 = torch.from_numpy(X_np1)\n",
    "\n",
    "data1 = prepare_data(A1,X1, tt_idx = 28, embedding_dim=embedding_dim, \n",
    "                    LAN_np = LAN_np, weighted = True) # Set LAN_np = None to train without language embeddings\n",
    "\n",
    "A_norm1,X_norm1,A_train1,A_valid,X_test1 = data1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e2a886-5d50-4dcb-97cb-a5478f70235a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Define feature groups for ablation\n",
    "feature_groups = {\n",
    "    \"GDP\": [0],\n",
    "    \"GINI\": [1],\n",
    "    \"HDI\": [2],\n",
    "    \"PTS\": [3],\n",
    "    \"U5M\": [4],\n",
    "    \"Language_Embeddings\": list(range(5, 17))  # Treat all language embeddings as one chunk\n",
    "}\n",
    "\n",
    "# Set number of epochs for retraining\n",
    "num_epochs_retrain = 500\n",
    "\n",
    "# Use the validation set for performance evaluation\n",
    "validation_index = 0  # Index of the validation time point to evaluate on\n",
    "\n",
    "# Retrain the baseline model (no masking) with 500 epochs\n",
    "print(\"\\nRetraining baseline model with 500 epochs...\")\n",
    "baseline_model_retrained = EGCU_H(\n",
    "    input_dim=input_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    output_dim=output_dim,\n",
    "    num_gcn_layers=num_gcn_layers,\n",
    "    num_heads=num_heads,\n",
    "    attention=True\n",
    ").to(device)\n",
    "\n",
    "link_predictor_baseline_retrained = LinkPredictorMLP(input_dim=output_dim, weighted=True).to(device)\n",
    "optimizer_baseline_retrained = optim.Adam(\n",
    "    list(baseline_model_retrained.parameters()) + list(link_predictor_baseline_retrained.parameters()), \n",
    "    lr=learning_rate\n",
    ")\n",
    "\n",
    "# Train baseline retrained model\n",
    "train(\n",
    "    X_norm=X_norm, A_norm=A_norm, A_train=A_train,\n",
    "    model=baseline_model_retrained, link_predictor=link_predictor_baseline_retrained,\n",
    "    criterion=criterion, optimizer=optimizer_baseline_retrained,\n",
    "    device=device, num_epochs=num_epochs_retrain, edge_subset=edge_subset,\n",
    "    loss_weights=loss_weights, calc_reverse=calc_reverse,\n",
    "    save_at=50, weighted=True\n",
    ")\n",
    "\n",
    "# Evaluate the retrained baseline model on the validation set\n",
    "_, baseline_mse_retrained = eval_model(\n",
    "    X_norm=X_norm1,\n",
    "    A_norm=A_norm1,\n",
    "    A_test=A_valid,  # Use the validation set for evaluation\n",
    "    model=baseline_model_retrained,\n",
    "    link_predictor=link_predictor_baseline_retrained,\n",
    "    device=device,\n",
    "    predict_indx=validation_index,  # Select the validation time point\n",
    "    loss_all=False,\n",
    "    weighted=True\n",
    ")\n",
    "print(f\"Baseline MSE on Validation Set (retrained): {baseline_mse_retrained}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92942239-a802-467e-844f-cd927a30e722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform ablation study with retraining\n",
    "retrain_mse = {}\n",
    "feature_importance_retrain_500 = {}\n",
    "\n",
    "for group_name, indices in feature_groups.items():\n",
    "    print(f\"\\nExcluding {group_name} features and retraining with 500 epochs...\")\n",
    "\n",
    "    # Mask out the features for this group\n",
    "    X_masked = X_norm.clone()\n",
    "    X_masked[..., indices] = 0  # Mask the features for the group\n",
    "\n",
    "    # Retrain the model with the masked features\n",
    "    model_retrain_500 = EGCU_H(\n",
    "        input_dim=input_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        output_dim=output_dim,\n",
    "        num_gcn_layers=num_gcn_layers,\n",
    "        num_heads=num_heads,\n",
    "        attention=True\n",
    "    ).to(device)\n",
    "\n",
    "    link_predictor_retrain_500 = LinkPredictorMLP(input_dim=output_dim, weighted=True).to(device)\n",
    "    optimizer_retrain_500 = optim.Adam(\n",
    "        list(model_retrain_500.parameters()) + list(link_predictor_retrain_500.parameters()), \n",
    "        lr=learning_rate\n",
    "    )\n",
    "\n",
    "    train(\n",
    "        X_norm=X_masked, A_norm=A_norm, A_train=A_train,\n",
    "        model=model_retrain_500, link_predictor=link_predictor_retrain_500,\n",
    "        criterion=criterion, optimizer=optimizer_retrain_500,\n",
    "        device=device, num_epochs=num_epochs_retrain, edge_subset=edge_subset,\n",
    "        loss_weights=loss_weights, calc_reverse=calc_reverse,\n",
    "        save_at=50, weighted=True\n",
    "    )\n",
    "\n",
    "    X_masked1 = X_norm1.clone()\n",
    "    X_masked1[..., indices] = 0  # Mask the features for the group\n",
    "\n",
    "    # Evaluate the retrained model on the validation set\n",
    "    _, retrain_mse_500 = eval_model(\n",
    "        X_norm=X_masked1,\n",
    "        A_norm=A_norm1,\n",
    "        A_test=A_valid,  # Use the validation set for evaluation\n",
    "        model=model_retrain_500,\n",
    "        link_predictor=link_predictor_retrain_500,\n",
    "        device=device,\n",
    "        predict_indx=validation_index,  # Select the validation time point\n",
    "        loss_all=False,\n",
    "        weighted=True\n",
    "    )\n",
    "    print(f\"MSE on Validation Set after excluding {group_name} (500 epochs): {retrain_mse_500}\")\n",
    "\n",
    "    retrain_mse[group_name] = retrain_mse_500\n",
    "    \n",
    "    # Calculate the performance decrease (as MSE is minimized, higher MSE indicates worse performance)\n",
    "    performance_decrease = 100 * (retrain_mse_500 - baseline_mse_retrained) / baseline_mse_retrained\n",
    "    feature_importance_retrain_500[group_name] = performance_decrease\n",
    "\n",
    "# Print feature importance\n",
    "print(\"\\nFeature Importance (Performance Decrease in % based on Validation Set):\")\n",
    "for group_name, decrease in feature_importance_retrain_500.items():\n",
    "    print(f\"{group_name}: {decrease:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40553b37-6327-47f9-9f99-8ced5f9403c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance.keys()\n",
    "key_mapping = {\n",
    "    'Language_Embeddings' : 'Language', \n",
    "    'U5M' : 'Mortality under 5', \n",
    "    'PTS' : 'Political Terror Scale', \n",
    "    'HDI' : 'Human Development Index',\n",
    "    'GINI' : 'GINI index', \n",
    "    'GDP' : 'GDP per capita'\n",
    "}\n",
    "\n",
    "feature_importance_retrain_500 = {\n",
    "    key_mapping.get(key, key): value for key, value in feature_importance_retrain_500.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d1dc3f-95a9-422f-ba81-0cac4a193eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse the order of features and their corresponding performance impacts\n",
    "feature_names = list(feature_importance_retrain_500.keys())\n",
    "performance_increases = list(feature_importance_retrain_500.values())\n",
    "\n",
    "feature_names = feature_names[::-1]\n",
    "performance_increases = performance_increases[::-1]\n",
    "\n",
    "# Create the horizontal bar chart\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.barh(feature_names, performance_increases, color='skyblue', alpha=0.8)\n",
    "#plt.ylabel('Feature Groups', fontsize=14)\n",
    "plt.xlabel('Performance Decrease (%)', fontsize=14)\n",
    "plt.title('Feature Ablation Performance Loss', fontsize=16)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "# Add a dotted line at the zero point\n",
    "plt.axvline(x=0, color=\"gray\", linestyle=\"--\", linewidth=0.8)\n",
    "\n",
    "# Remove grid\n",
    "plt.grid(False)\n",
    "\n",
    "# Despine by removing top and right spines\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "# Display the bar chart\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
